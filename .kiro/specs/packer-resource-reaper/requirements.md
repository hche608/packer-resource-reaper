# Requirements Document

## Introduction

The AWS Packer Resource Reaper is a serverless application that acts as an external watchdog to identify and clean up "zombie" EC2 instances and their directly associated resources left behind by failed or interrupted Packer builds. The system operates within a single AWS account and region, providing a simple, stateless cleanup mechanism.

## Glossary

- **Reaper**: The serverless application that identifies and cleans up zombie resources
- **Zombie_Instance**: An EC2 instance left running after a failed Packer build
- **Temporal_Filter**: Age-based filtering mechanism using a global MaxInstanceAge threshold
- **Identity_Filter**: SSH key pair pattern-based filtering for Packer-related resources
- **Packer_KeyPair**: SSH key pairs automatically generated by Packer with the naming pattern "packer_<random_value>"
- **Cleanup_Engine**: The component responsible for executing resource termination and deletion
- **Dry_Run_Mode**: A safety mechanism that simulates cleanup operations without executing destructive actions

## Requirements

### Requirement 1: Resource Identification and Filtering

**User Story:** As a DevOps engineer, I want the system to accurately identify Packer-related zombie instances, so that only appropriate resources are cleaned up without affecting production workloads.

#### Acceptance Criteria

1.1. WHEN an EC2 instance exceeds the configured MaxInstanceAge threshold, THE Temporal_Filter SHALL mark it as a candidate for cleanup
1.2. WHEN scanning instances, THE Identity_Filter SHALL identify instances launched with KeyPairs matching the pattern "packer_*" (Packer_KeyPair)
1.3. WHEN both filters are applied, THE Reaper SHALL only target instances that match BOTH criteria (key pair pattern AND age threshold)

**⚠️ IMPORTANT WARNING:** Instances are detected by the name of the SSH key that is automatically generated by Packer (pattern: `packer_*`). Do NOT use this application if you use similar key naming patterns (e.g., `packer_mykey`, `packer_production`) for non-Packer instances, as they may be incorrectly identified and terminated.

### Requirement 2: Dependency-Aware Resource Cleanup Order

**User Story:** As a system administrator, I want resources to be cleaned up in the correct order, so that dependency violations are avoided and cleanup operations complete successfully.

#### Acceptance Criteria

2.1. WHEN cleanup is initiated, THE Cleanup_Engine SHALL first identify Zombie_Instances
2.2. WHEN Zombie_Instances are identified, THE Cleanup_Engine SHALL collect directly associated resources (Packer_KeyPair, Security Group, attached EBS volumes, associated EIP, IAM instance profile)
2.3. WHEN associated resources are collected, THE Cleanup_Engine SHALL terminate EC2 instances and wait for termination confirmation
2.4. WHEN instances are terminated, THE Cleanup_Engine SHALL delete the directly associated resources collected previously (including IAM instance profiles matching `packer_*` pattern)
2.5. WHEN terminating instances, THE Cleanup_Engine SHALL wait for termination confirmation before proceeding to dependent resources
2.6. WHEN deleting Security Groups, THE Cleanup_Engine SHALL handle DependencyViolation errors gracefully (resource will be re-identified in next execution)
2.7. IF an instance is in shutting-down state, THEN THE Cleanup_Engine SHALL defer associated resource deletion to the next scheduled execution
2.8. THE Cleanup_Engine SHALL only delete resources that were directly associated with the terminated Zombie_Instance

### Requirement 3: Stateless Execution

**User Story:** As a platform engineer, I want the Reaper to be completely stateless, so that it is simple to operate and doesn't require any external database or state storage.

#### Acceptance Criteria

3.1. WHEN executing, THE Reaper SHALL perform a fresh scan of resources without relying on previous execution state
3.2. THE Reaper SHALL NOT require any database, DynamoDB table, or state persistence mechanism
3.3. IF a resource could not be deleted in a previous run, THEN THE Reaper SHALL re-identify it in the next execution and attempt cleanup again
3.4. THE Reaper SHALL NOT track or store information about resources between executions

### Requirement 4: Scheduled Execution and Monitoring

**User Story:** As a DevOps engineer, I want the Reaper to run automatically on a schedule, so that Zombie_Instances are cleaned up without manual intervention.

#### Acceptance Criteria

4.1. WHEN configured, THE Reaper SHALL trigger execution at the specified frequency using EventBridge
4.2. WHEN the Reaper executes, THE Reaper SHALL log all scanned resources and actions taken to CloudWatch
4.3. WHEN sending notifications, THE Reaper SHALL include instance ID, type, termination reason, and list of deleted associated resources
4.4. WHEN cleanup actions are performed, THE Reaper SHALL send SNS notifications

### Requirement 5: Configuration and Deployment

**User Story:** As a platform engineer, I want to deploy and configure the Reaper easily with minimal configuration options.

#### Acceptance Criteria

5.1. THE Reaper SHALL be deployable using AWS SAM templates
5.2. WHEN deploying, THE Reaper SHALL support configuration via environment variables for MaxInstanceAge, check rate, LOG_LEVEL, and BATCH_DELETE_SIZE
5.3. WHEN configuring IAM permissions, THE Reaper SHALL follow least privilege principles
5.4. WHEN deployed, THE Reaper SHALL operate entirely within AWS infrastructure without dependencies on external machines

### Requirement 6: Error Handling and Resilience

**User Story:** As a system administrator, I want the Reaper to handle errors gracefully, so that temporary failures don't prevent future cleanup operations.

#### Acceptance Criteria

6.1. WHEN encountering DependencyViolation errors, THE Reaper SHALL log the error and continue (resource will be re-identified in next execution)
6.2. WHEN API rate limits are encountered, THE Reaper SHALL implement exponential backoff retry logic
6.3. WHEN cleanup operations fail, THE Reaper SHALL log detailed error information to CloudWatch
6.4. IF an instance is in a hung or rebooting state, THEN THE Reaper SHALL still attempt termination

### Requirement 7: Security and Access Control

**User Story:** As a security engineer, I want the Reaper to operate with minimal required permissions.

#### Acceptance Criteria

7.1. WHEN executing, THE Reaper SHALL use IAM roles with permissions restricted to necessary EC2, IAM, and related actions for cleanup
7.2. WHEN accessing resources, THE Reaper SHALL only operate on resources that match the configured filters (including IAM instance profiles matching `packer_*` pattern)
7.3. THE Reaper SHALL NOT require or store any long-term credentials or access keys
7.4. WHEN logging operations, THE Reaper SHALL NOT expose sensitive information in CloudWatch logs

### Requirement 8: Single Account and Region Scope

**User Story:** As a platform engineer, I want the Reaper to operate strictly within the current AWS account and region, so that there is no risk of accidentally affecting resources in other accounts or regions.

#### Acceptance Criteria

8.1. THE Reaper SHALL NOT support cross-account role assumption or operations
8.2. THE Reaper SHALL NOT scan or modify resources in AWS accounts other than where it is deployed
8.3. THE Reaper SHALL NOT support cross-region operations or resource discovery
8.4. THE Reaper SHALL NOT scan or modify resources in AWS regions other than where it is deployed
8.5. THE Reaper SHALL use the default AWS credentials and region from the Lambda execution environment
8.6. WHEN deployed, THE Reaper SHALL be scoped to exactly one AWS account and one AWS region

### Requirement 9: Dry Run and Safety Operations

**User Story:** As a system administrator, I want to test the Reaper's behavior safely, so that I can validate its operation before allowing destructive actions.

#### Acceptance Criteria

9.1. WHEN the DRY_RUN environment variable is set to "true", THE Reaper SHALL identify all cleanup candidates without executing destructive operations
9.2. WHEN operating in Dry_Run_Mode, THE Reaper SHALL log all resources that would be deleted to CloudWatch at INFO level (visible in default configuration)
9.3. WHEN operating in Dry_Run_Mode, THE Reaper SHALL send a simulation report via SNS detailing planned actions
9.4. WHEN operating in Dry_Run_Mode, THE Reaper SHALL NOT execute any terminate, delete, or release API calls
9.5. WHEN transitioning from Dry_Run_Mode to live mode, THE Reaper SHALL require explicit configuration change (DRY_RUN must be explicitly set to "false")

**Safety Note:** The SAM template defaults DRY_RUN to "true", preventing accidental destructive operations on first deployment.

### Requirement 10: Orphaned Packer Resource Cleanup

**User Story:** As a DevOps engineer, I want the Reaper to clean up orphaned Packer-created resources that persist after builds complete or fail, so that my AWS account doesn't accumulate unused resources and incur unnecessary costs.

#### Acceptance Criteria

10.1. WHEN scanning for orphaned resources, THE Reaper SHALL identify EC2 key pairs with names starting with `packer_` that are not associated with any running or pending EC2 instances
10.2. WHEN scanning for orphaned resources, THE Reaper SHALL identify security groups with names or descriptions containing `packer` that are not attached to any EC2 instances or network interfaces
10.3. WHEN scanning for orphaned resources, THE Reaper SHALL identify IAM roles with names starting with `packer_` that are not attached to any EC2 instance profiles in use
10.4. WHEN orphaned Packer_KeyPairs are identified, THE Cleanup_Engine SHALL delete them after confirming no instances reference them
10.5. WHEN orphaned Packer security groups are identified, THE Cleanup_Engine SHALL delete them after confirming no dependencies exist
10.6. WHEN orphaned Packer IAM roles are identified, THE Cleanup_Engine SHALL detach all policies and delete the role after confirming no instance profiles reference them
10.7. WHEN primary zombie instance cleanup completes, THE orphaned resource cleanup SHALL execute as an additional step
10.8. WHEN deleting orphaned resources, THE Cleanup_Engine SHALL apply the same Dry_Run_Mode behavior as primary cleanup operations
10.9. WHEN orphaned resources are cleaned up, THE Reaper SHALL log each deleted resource type and identifier to CloudWatch
10.10. WHEN orphaned resources are cleaned up, THE Reaper SHALL include orphaned resource details in SNS notifications
10.11. WHEN scanning for orphaned resources, THE Reaper SHALL only consider resources older than the configured age threshold (default: 2 hours, minimum: 1 hour) to prevent race conditions with active Packer builds that are still provisioning
10.12. WHEN a key pair or IAM role is younger than the age threshold, THE Reaper SHALL skip it and log a debug message explaining why it was skipped

**⚠️ CRITICAL SAFETY NOTE:** Orphaned resource cleanup includes age-based filtering to prevent a race condition where resources created by an active Packer build could be deleted before provisioning completes. Key pairs and IAM roles must be older than `max_resource_age_hours` (default: 2 hours) before they are considered for cleanup.

### Requirement 11: Configurable Log Level

**User Story:** As a DevOps engineer, I want to configure the log level via environment variable, so that I can get detailed logs during debugging while reducing log volume and costs in production.

#### Acceptance Criteria

11.1. WHEN the LOG_LEVEL environment variable is set, THE Reaper SHALL use the specified log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
11.2. WHEN the LOG_LEVEL environment variable is not set, THE Reaper SHALL default to INFO level
11.3. WHEN LOG_LEVEL is set to DEBUG, THE Reaper SHALL output detailed information including API calls, resource attributes, and processing steps
11.4. WHEN LOG_LEVEL is set to ERROR or higher, THE Reaper SHALL only output error conditions and critical failures
11.5. WHEN an invalid LOG_LEVEL value is provided, THE Reaper SHALL default to INFO level and log a warning

### Requirement 12: Batch Delete Operations

**User Story:** As a platform engineer, I want to configure batch deletion with concurrent processing, so that I can optimize cleanup performance for environments with many zombie resources while maintaining control over deletion rate.

#### Acceptance Criteria

12.1. WHEN the BATCH_DELETE_SIZE environment variable is set, THE Cleanup_Engine SHALL process deletions in batches of the specified size
12.2. WHEN the BATCH_DELETE_SIZE environment variable is not set, THE Cleanup_Engine SHALL default to 1 (sequential deletion, no batching)
12.3. WHEN batch deletion is enabled (BATCH_DELETE_SIZE > 1), THE Cleanup_Engine SHALL process multiple resource deletions concurrently within each batch using ThreadPoolExecutor (NOT asyncio, since boto3 is synchronous)
12.4. WHEN processing a batch, THE Cleanup_Engine SHALL wait for all deletions in the current batch to complete before proceeding to the next batch
12.5. WHEN a deletion fails within a batch, THE Cleanup_Engine SHALL log the failure and continue processing remaining items in the batch
12.6. WHEN batch deletion is used, THE Cleanup_Engine SHALL still respect the dependency-aware cleanup order (instances before dependent resources)
12.7. WHEN BATCH_DELETE_SIZE is set to an invalid value (non-positive integer), THE Cleanup_Engine SHALL default to 1 and log a warning

**Implementation Note:** The batch processor uses `ThreadPoolExecutor` because boto3 is synchronous (blocking). Using `asyncio.gather` with blocking boto3 calls would execute sequentially on the main thread, defeating the purpose of concurrent processing.
